{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS579: Lecture 23  \n",
    "*[Dr. Aron Culotta](http://cs.iit.edu/~culotta)*  \n",
    "*[Illinois Institute of Technology](http://iit.edu)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Review**\n",
    "\n",
    "- l10 -> end\n",
    "- sentiment analysis\n",
    "  - lexicons\n",
    "  - wordnet\n",
    "  - how to combine words with different sentiment?\n",
    "- classification\n",
    "  - workflow (collect, label, train, test, etc)\n",
    "  - computing feature vectors\n",
    "  - generalization error\n",
    "  - variants of SimpleMachine\n",
    "  - computing cross-validation accuracy (why?)\n",
    "  - bias vs. variance\n",
    "- demographics\n",
    "  - pitfalls of using name lists\n",
    "  - computing odds ratio\n",
    "  - smoothing\n",
    "  - ngrams\n",
    "  - tokenization\n",
    "  - stop words\n",
    "  - regularization (why?)\n",
    "- logistic regression, linear regression\n",
    "  - no need to do calculus, but do you understand the formula?\n",
    "  - apply classification function given data/parameters\n",
    "  - what does the gradient represent?\n",
    "- feature representation\n",
    "  - tf-idf\n",
    "  - csr_matrix: how does this data structure work? (data, column index, row pointer)\n",
    "- recommendation systems\n",
    "  - content-based\n",
    "    - tf-idf\n",
    "    - cosine similarity\n",
    "  - collaborative filtering\n",
    "    - user-user\n",
    "    - item-item\n",
    "    - measures: jaccard, cosine, pearson. Why choose one over another\n",
    "  - How to compute the recommended score for a specific item?\n",
    "- k-means\n",
    "  - compute cluster assignment, means, and error function\n",
    "  - what effect does k have?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>[horror, horror, romance, romance, romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456</td>\n",
       "      <td>[romance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                       tokens\n",
       "0      123  [horror, horror, romance, romance, romance]\n",
       "1      456                                    [romance]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movies = pd.DataFrame([[123, ['horror', 'horror', 'romance', 'romance', 'romance']],\n",
    "                       [456, ['romance']]],\n",
    "                      columns=['movieId', 'tokens'])\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>[horror, horror, romance, romance, romance]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456</td>\n",
       "      <td>[romance]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                       tokens\n",
       "0      123  [horror, horror, romance, romance, romance]\n",
       "1      456                                    [romance]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# querying with pandas.\n",
    "import numpy as np\n",
    "# movies.sort_values('movieId', ascending=False)\n",
    "movies[(movies['movieId'] == 123) | (movies['movieId'] < 500)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf-idf**  \n",
    "traditional definition:\n",
    "\n",
    "$$tfidf(i, d) = \\frac{tf(i, d)}{max_k tf(k, d)} * log10(N/df(i))$$\n",
    "\n",
    "- df(horror) = 1\n",
    "- df(romance) = 2\n",
    "\n",
    "- tf (horror, 123) = 2\n",
    "- tfidf(horror, 123) = 2 / 3 * log10(2/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dot products.\n",
    "from scipy.sparse import csr_matrix\n",
    "a = csr_matrix([1, 2, 3, 0, 0, 0, 5])\n",
    "b = csr_matrix([4, 5, 6, 0, 0, 0, 0])\n",
    "a.dot(b.T).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[5, 7, 9, 0, 0, 0, 5]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a + b).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 0 0 0 5]]\n",
      "[[1]\n",
      " [2]\n",
      " [3]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [5]]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "print(a.todense())\n",
    "print(a.T.todense())\n",
    "print(a.dot(b.T).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOT this!\n",
    "a.todense().dot(b.T.todense()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And definitely not this:\n",
    "total = 0\n",
    "for i in range(a.shape[1]):\n",
    "    total += a[0, i] * b[0, i]\n",
    "total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How to construct a csr_matrix? **\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "\n",
    "We'll use:\n",
    "\n",
    "```\n",
    "csr_matrix((data, (row_ind, col_ind)), [shape=(M, N)])\n",
    "where data, row_ind and col_ind satisfy the relationship a[row_ind[k], col_ind[k]] = data[k]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices: [0 1 5 0 1 2]\n",
      "indptr: [0 3 6]\n",
      "data: [1 2 3 4 5 6]\n",
      "\n",
      "setting (0,2) to 10\n",
      "\n",
      "indices: [0 1 2 5 0 1 2]\n",
      "indptr: [0 4 7]\n",
      "data: [ 1  2 10  3  4  5  6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    }
   ],
   "source": [
    "# why modifying a csr_matrix is slow:\n",
    "m = csr_matrix([[1,2,0,0,0,3], [4,5,6,0,0,0]])\n",
    "print('indices:', m.indices)  # columns of each non-zero value\n",
    "print('indptr:', m.indptr)   # index into m.indices/m.data for start of each row\n",
    "print('data:', m.data)     # non-zero values\n",
    "m[0,2] = 10\n",
    "print('\\nsetting (0,2) to 10\\n')\n",
    "print('indices:', m.indices)\n",
    "print('indptr:', m.indptr)\n",
    "print('data:', m.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [list([1, 2, 3]) list([4, 5, 6])]\n",
      "rows: [list([0, 1, 5]) list([0, 1, 2])]\n",
      "\n",
      "setting (0,2) to 10\n",
      "\n",
      "data: [list([1, 2, 10, 3]) list([4, 5, 6])]\n",
      "rows: [list([0, 1, 2, 5]) list([0, 1, 2])]\n",
      "[[ 1  2 10  0  0  3]\n",
      " [ 4  5  6  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# what does a lil_matrix look like?\n",
    "from scipy.sparse import lil_matrix\n",
    "m = lil_matrix([[1,2,0,0,0,3], [4,5,6,0,0,0]])\n",
    "print('data:', m.data)\n",
    "print('rows:', m.rows)\n",
    "print('\\nsetting (0,2) to 10\\n')\n",
    "m[0,2] = 10\n",
    "print('data:', m.data)\n",
    "print('rows:', m.rows)\n",
    "print(m.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = lil_matrix((2, 10))\n",
    "# for loop; update m[i,j] = x\n",
    "m[0,2] = 10\n",
    "m.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/sparse/compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 10.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = csr_matrix((5, 8))\n",
    "m[3, 5] = 10\n",
    "m.indices\n",
    "m.indptr\n",
    "m.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf: [0.6666666666666666, 1.0]\n",
      "idf_weight: [0.3010299956639812, 0.0]\n",
      "tf: [1.0]\n",
      "idf_weight: [0.0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tokens</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123</td>\n",
       "      <td>[horror, horror, romance, romance, romance]</td>\n",
       "      <td>(0, 0)\\t0.200686663776\\n  (0, 1)\\t0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456</td>\n",
       "      <td>[romance]</td>\n",
       "      <td>(0, 1)\\t0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                                       tokens  \\\n",
       "0      123  [horror, horror, romance, romance, romance]   \n",
       "1      456                                    [romance]   \n",
       "\n",
       "                                  features  \n",
       "0    (0, 0)\\t0.200686663776\\n  (0, 1)\\t0.0  \n",
       "1                              (0, 1)\\t0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import math\n",
    "def featurize(movies):\n",
    "    dfs = Counter()\n",
    "    data = []\n",
    "    rows = []\n",
    "    cols = []\n",
    "    # set document frequencies\n",
    "    for tokens in movies['tokens']:\n",
    "        dfs.update(set(tokens))  # note set! \n",
    "                                 # count each term once per doc\n",
    "        # dfs += set(tokens)  # will create a new copy...slow\n",
    "    vocab = {v: i for i, v in enumerate(sorted(dfs))}\n",
    "    N = len(movies)\n",
    "    n_cols = len(vocab)\n",
    "    vectors = []  # list of csr_matrices, one per movie\n",
    "    for tokens in movies.tokens:\n",
    "        tfs = Counter(tokens)\n",
    "        maxtf = max(tfs.values())\n",
    "        rows = [0] * len(tfs)  # row indices are all 0\n",
    "        cols = [vocab[t] for t in tfs] # col indices are feautre indices\n",
    "        # values are tf-idf: tf(i, d) / max_k tf(k, d) * log10(N/df(i))\n",
    "        data = [v / maxtf * math.log10(N / dfs[t])\n",
    "                for t, v in tfs.items()]\n",
    "        print('tf:', [v / maxtf for t, v in tfs.items()])\n",
    "        print('idf_weight:', [math.log10(N / dfs[t]) for t, v in tfs.items()])\n",
    "\n",
    "        # construct the matrix for this movie\n",
    "        vectors.append(csr_matrix((data, (rows, cols)),\n",
    "                                   shape=(1, n_cols)))\n",
    "        \n",
    "    movies['features'] = vectors\n",
    "    return movies, vocab\n",
    "\n",
    "movies, vocab = featurize(movies)\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.20068666,  0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['features'][0].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040275137017536239"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['features'][0].dot(movies['features'][0].T).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br><br><br>\n",
    "## Privacy and Ethics in OSNA\n",
    "\n",
    "<br><br><br><br><br><br><br>\n",
    "<br><br><br><br><br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![harvard](images/harvard.png)\n",
    "[source](https://www.chronicle.com/article/Harvards-Privacy-Meltdown/128166)\n",
    "- A study to measure homophily in Facebook\n",
    "  - Do friends have similar tastes in books/music/etc.\n",
    "- Questions about data collection process\n",
    "- Easy to de-anonymize\n",
    "> ... a privacy scholar at the University of Wisconsin at Milwaukee, Michael Zimmer, showed that the \"anonymous\" data of Mr. Kaufman and his colleagues could be cracked to identify the source as Harvard undergraduates.\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "![fb](images/fb.png)\n",
    "[source](https://www.nytimes.com/2014/06/30/technology/facebook-tinkers-with-users-emotions-in-news-feed-experiment-stirring-outcry.html)\n",
    "- A study by Facebook to measure how your feed affects your mood\n",
    "  - Manipulated the feed of ~600k users by altering number of positive/negative posts the user sees\n",
    "  - Measured the positive/negative posts the user then wrote\n",
    "> Although academic protocols generally call for getting people’s consent before psychological research is conducted on them, Facebook didn’t ask for explicit permission from those it selected for the experiment. It argued that its 1.28 billion monthly users gave blanket consent to the company’s research as a condition of using the service.\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "![rec](images/rec.png)\n",
    "[source](https://spectrum.ieee.org/tech-talk/telecom/internet/women-less-likely-to-be-shown-ads-for-highpaying-jobs)\n",
    "- Fairness in recommendation systems\n",
    "- Experiment: create fake Google profiles, then search for jobs\n",
    "- Only difference was gender\n",
    "> The male profiles were much more likely to be shown ads for a career coaching service for executive positions paying over $200,000. The Google ad network showed this ad to the male users more than 1800 times, but only about 300 times to women.\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "![pro](images/pro.png)\n",
    "<img src=\"images/housing.png\" width=400>\n",
    "[source](https://www.propublica.org/article/facebook-advertising-discrimination-housing-race-sex-national-origin)\n",
    "- Facebook let you advertise apartment rentals while excluding people based on ethnicity\n",
    "\n",
    "> Last week, ProPublica bought dozens of rental housing ads on Facebook, but asked that they not be shown to certain categories of users, such as African Americans, mothers of high school kids, people interested in wheelchair ramps, Jews, expats from Argentina and Spanish speakers.  \n",
    "All of these groups are protected under the federal Fair Housing Act, which makes it illegal to publish any advertisement “with respect to the sale or rental of a dwelling that indicates any preference, limitation, or discrimination based on race, color, religion, sex, handicap, familial status, or national origin.” Violators can face tens of thousands of dollars in fines.  \n",
    "**Every single ad was approved within minutes.**\n",
    "\n",
    "\n",
    "<br><br><br><br><br><br>\n",
    "\n",
    "Many ethical issues in online social network analysis:\n",
    "\n",
    "- **Privacy**: What data can be collected? shared? with whom?\n",
    "- **Consent**: Scientists are bound by ethical guidelines when conducting research involving humans.\n",
    "- **Fairness**: When algorithms are used to make decisions about people, they must not discriminate based on protected classes of people (e.g., by gender, race/ethnicity, sexual orientation, etc.).\n",
    "\n",
    "**How can we decide if our behavior is ethical?**\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "**[Belmont Report](https://en.wikipedia.org/wiki/Belmont_Report)**\n",
    "- Ethical guidelines published in 1979\n",
    "- Response to notorious [Tuskegee syphilis experiments](https://en.wikipedia.org/wiki/Tuskegee_syphilis_experiment)\n",
    "  - 40 year study by U.S. Public Health Service on population of impoverished African Americans in Alabama\n",
    "  > Researchers knowingly failed to treat patients appropriately after the 1940s validation of penicillin was found as an effective cure for the disease they were studying.\n",
    "  \n",
    "**Three ethical principals outlines in Belmont Report**\n",
    "\n",
    "1. **Respect for persons:** protecting the autonomy of all people and treating them with courtesy and respect and allowing for informed consent.\n",
    "  - Researchers must be truthful and conduct no deception\n",
    "  - Subjects enter into the research voluntarily and with adequate information  \n",
    "<br><br>\n",
    "2. **Beneficence:** The philosophy of \"Do no harm\" while maximizing benefits for the research project and minimizing risks to the research subjects\n",
    "<br><br>\n",
    "3. **Justice:** ensuring reasonable, non-exploitative, and well-considered procedures are administered fairly — the fair distribution of costs and benefits to potential research participants — and equally.\n",
    "\n",
    "Applying the above principals leads to the following requirements:\n",
    "\n",
    "1. **Informed Consent:**  Respect for persons requires that subjects, to the degree that they are capable, be given the opportunity to choose what shall or shall not happen to them. \n",
    "<br><br>\n",
    "2. **Assessment of Risks and Benefits:** We must protect against risk of harm to subjects and also consider loss of the substantial benefits that might be gained from research.\n",
    "  - Are the expected benefits of the research worth the cost?\n",
    "<br><br>  \n",
    "3. **Selection of Subjects:** Potentially beneficial research should not be restricted only to some subjects; nor should only \"undesirable\" persons be selected for risky research.\n",
    "\n",
    "\n",
    "<br><br><br><br>\n",
    "** Institutional Review Board:**\n",
    "- Every university has a panel of faculty that assess a proposed research project by the above criteria\n",
    "- Much of social media research can be deemed \"non human subjects\" research if passively observing public data:\n",
    "  > Research involving collection or study of existing data, documents, records, pathological specimens, or diagnostic specimens: (i) if these sources are publicly available; or (ii) if the information is recorded by the investigator in such a manner that subjects cannot be identified, directly or through identifiers linked to the subjects\n",
    "\n",
    "<br><br><br><br>\n",
    "**Challenges in applying these principals to OSNA**\n",
    "\n",
    "- Do users know which data is private?\n",
    "![privacy](images/privacy.png)\n",
    "[source](https://www.usnews.com/opinion/articles/2012/12/28/is-facebooks-privacy-policy-too-confusing)\n",
    "> The family photo posted by Zuckerberg showed up on the newsfeed of Vox Media's Callie Schweitzer because they have a mutual friend, but Zuckerberg did not intend for the photo to become public. She said it was \"way uncool\" for Schweitzer to post the private photo to Twitter.\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "- How can we ensure anonymity?\n",
    "![aol](images/aol.png)\n",
    "[source](https://techcrunch.com/2006/08/06/aol-proudly-releases-massive-amounts-of-user-search-data/)\n",
    ">  AOL has released very private data about its users without their permission. While the AOL username has been changed to a random ID number, the abilitiy to analyze all searches by a single user will often lead people to easily determine who the user is, and what they are up to. The data includes personal names, addresses, social security numbers and everything else someone might type into a search box.\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "- How can we ensure fairness?\n",
    "![kleinberg](images/kleinberg.png)\n",
    "> Recent discussion in the public sphere about algorithmic classification has involved tension between competing notions of what it means for a probabilistic classification to be fair to different groups. We formalize three fairness conditions that lie at the heart of these debates, and we prove that except in highly constrained special cases, there is no method that can satisfy these three conditions simultaneously. \n",
    "\n",
    "\n",
    "**Conclusion**\n",
    "- Think carefully before conducting studies involving human data\n",
    "- Would a reasonable person be upset about how the research was conducted?\n",
    "- Have Institutional Review Board review research proposal\n",
    "- Get feedback from others working in the area"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
